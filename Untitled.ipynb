{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width     Species\n",
       "0            5.1          3.5           1.4          0.2      setosa\n",
       "1            4.9          3.0           1.4          0.2      setosa\n",
       "2            4.7          3.2           1.3          0.2      setosa\n",
       "3            4.6          3.1           1.5          0.2      setosa\n",
       "4            5.0          3.6           1.4          0.2      setosa\n",
       "5            5.4          3.9           1.7          0.4      setosa\n",
       "6            4.6          3.4           1.4          0.3      setosa\n",
       "7            5.0          3.4           1.5          0.2      setosa\n",
       "8            4.4          2.9           1.4          0.2      setosa\n",
       "9            4.9          3.1           1.5          0.1      setosa\n",
       "10           5.4          3.7           1.5          0.2      setosa\n",
       "11           4.8          3.4           1.6          0.2      setosa\n",
       "12           4.8          3.0           1.4          0.1      setosa\n",
       "13           4.3          3.0           1.1          0.1      setosa\n",
       "14           5.8          4.0           1.2          0.2      setosa\n",
       "15           5.7          4.4           1.5          0.4      setosa\n",
       "16           7.0          3.2           4.7          1.4  versicolor\n",
       "17           6.4          3.2           4.5          1.5  versicolor\n",
       "18           6.9          3.1           4.9          1.5  versicolor\n",
       "19           5.5          2.3           4.0          1.3  versicolor\n",
       "20           6.5          2.8           4.6          1.5  versicolor\n",
       "21           5.7          2.8           4.5          1.3  versicolor\n",
       "22           6.3          3.3           4.7          1.6  versicolor\n",
       "23           4.9          2.4           3.3          1.0  versicolor\n",
       "24           6.6          2.9           4.6          1.3  versicolor\n",
       "25           5.2          2.7           3.9          1.4  versicolor\n",
       "26           5.0          2.0           3.5          1.0  versicolor\n",
       "27           5.9          3.0           4.2          1.5  versicolor\n",
       "28           6.0          2.2           4.0          1.0  versicolor\n",
       "29           6.1          2.9           4.7          1.4  versicolor\n",
       "30           5.6          2.9           3.6          1.3  versicolor\n",
       "31           6.7          3.1           4.4          1.4  versicolor\n",
       "32           5.6          3.0           4.5          1.5  versicolor\n",
       "33           5.8          2.7           4.1          1.0  versicolor\n",
       "34           6.2          2.2           4.5          1.5  versicolor\n",
       "35           5.6          2.5           3.9          1.1  versicolor\n",
       "36           6.3          3.3           6.0          2.5   virginica\n",
       "37           5.8          2.7           5.1          1.9   virginica\n",
       "38           7.1          3.0           5.9          2.1   virginica\n",
       "39           6.3          2.9           5.6          1.8   virginica\n",
       "40           6.5          3.0           5.8          2.2   virginica\n",
       "41           7.6          3.0           6.6          2.1   virginica\n",
       "42           4.9          2.5           4.5          1.7   virginica\n",
       "43           7.3          2.9           6.3          1.8   virginica\n",
       "44           6.7          2.5           5.8          1.8   virginica\n",
       "45           7.2          3.6           6.1          2.5   virginica\n",
       "46           6.5          3.2           5.1          2.0   virginica\n",
       "47           6.4          2.7           5.3          1.9   virginica\n",
       "48           6.8          3.0           5.5          2.1   virginica\n",
       "49           5.7          2.5           5.0          2.0   virginica\n",
       "50           5.8          2.8           5.1          2.4   virginica\n",
       "51           6.4          3.2           5.3          2.3   virginica\n",
       "52           6.5          3.0           5.5          1.8   virginica\n",
       "53           7.7          3.8           6.7          2.2   virginica\n",
       "54           7.7          2.6           6.9          2.3   virginica\n",
       "55           6.0          2.2           5.0          1.5   virginica\n",
       "56           6.9          3.2           5.7          2.3   virginica\n",
       "57           5.6          2.8           4.9          2.0   virginica\n",
       "58           7.7          2.8           6.7          2.0   virginica\n",
       "59           6.3          2.7           4.9          1.8   virginica"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 4)\n",
      "(12, 4)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1].values  \n",
    "y = df.iloc[:, 4].values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=4)  \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 25):  \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Mean Error')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(range(1, 25), error, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')  \n",
    "plt.xlabel('K Value')  \n",
    "plt.ylabel('Mean Error')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.92\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 1]\n",
      " [0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      0.83      0.91         6\n",
      "   virginica       0.67      1.00      0.80         2\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        12\n",
      "   macro avg       0.89      0.94      0.90        12\n",
      "weighted avg       0.94      0.92      0.92        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virginica']\n"
     ]
    }
   ],
   "source": [
    "classes = {0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'}\n",
    "x_new = [[7.5, 3.5, 5.1, 2.3]]\n",
    "        #[5.5, 2.5, 4, 1.3],\n",
    "        #[5.1, 3.8, 1.9, 0.4]]\n",
    "        #[6.2, 3.4, 5.4, 2.3]\n",
    "y_pred = knn.predict(x_new)\n",
    "print(y_pred)\n",
    "#print(classes[y_pred[1]])\n",
    "#knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=4.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-0f72906452ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#train model with cv of 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcv_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#print each cv score (accuracy) and average them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    752\u001b[0m             tasks = BatchedCalls(itertools.islice(iterator, batch_size),\n\u001b[0;32m    753\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_nested_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m                                  self._pickle_cache)\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 \u001b[1;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, iterator_slice, backend_and_jobs, pickle_cache)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend_and_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_and_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    233\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m    234\u001b[0m     scores = parallel(\n\u001b[1;32m--> 235\u001b[1;33m         delayed(_fit_and_score)(\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    327\u001b[0m                 (\"Cannot have number of splits n_splits={0} greater\"\n\u001b[0;32m    328\u001b[0m                  \" than the number of samples: n_samples={1}.\")\n\u001b[1;32m--> 329\u001b[1;33m                 .format(self.n_splits, n_samples))\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=4."
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#create a new KNN model\n",
    "##knn_new = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#train model with cv of 5 \n",
    "#cv_scores = cross_val_score(knn_new, X, y, cv=5)\n",
    "\n",
    "#print each cv score (accuracy) and average them\n",
    "#print(cv_scores)\n",
    "#print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
